{"cells":[{"metadata":{"_uuid":"0f00231e-52f7-41a0-bce5-61c62d9448b8","_cell_guid":"ec7165b7-ea11-445a-808e-5c9c806aa282","trusted":true},"cell_type":"code","source":"# %% [code]\n# Importing libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# %% [code]\nfrom sklearn.model_selection import train_test_split\n\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.models import Sequential\nfrom keras.layers import Dense,Dropout,Embedding,LSTM,Conv2D,Flatten,MaxPooling2D\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.utils import to_categorical\n\n# %% [code]\n# reading Dataset and droping features\n\ndata = pd.read_csv(\"train_file.csv\")\ndata = data.drop(columns=['SentimentTitle','SentimentHeadline'],axis=1)\n# data = data.drop(columns=['IDLink', 'Title', 'Source', 'Topic', 'PublishDate','Facebook', 'GooglePlus', 'LinkedIn'],axis=1)\n\n# %% [code]\ndata.head()\n\n# %% [code]\nx_train = data\ny_train = data(columns=[['SentimentTitle','SentimentHeadline']])\n\n# %% [code]\n# Preprocessing the dataset\ntokenizer = Tokenizer(num_words=15000)\ntokenizer.fit_on_texts(list(x_train))\n\nX_train = tokenizer.texts_to_sequences(x_train)\nX_train = pad_sequences(X_train, maxlen=150)\nX_train\n\n# %% [code]\ny_train=np.array(y_train).reshape((55932,1))\n\n# %% [code]\ntrain_x, val_x, train_y, val_y = train_test_split(X_train, y_train, test_size=0.2)\n\n# %% [code]\n# Creating a LSTM model\nmodel=Sequential()\nmodel.add(Embedding(15000,512,mask_zero=True))\nmodel.add(LSTM(512,dropout=0.1, recurrent_dropout=0.1,return_sequences=True))\nmodel.add(LSTM(256,dropout=0.1, recurrent_dropout=0.1,return_sequences=False))\nmodel.add(Dense(1,activation='softmax'))\nmodel.compile(loss='mean_squared_error',optimizer='Adam',metrics=['mean_squared_error'])\n# model.compile(loss='binary_crossentropy',optimizer='rmsprop',metrics=['accuracy'])\nmodel.summary()\n\n# %% [code]\n# Fitting the dataset into the model\nmodel.fit(train_x[:2000], train_y[:2000], validation_data=(val_x, val_y), epochs=4, batch_size=128, verbose=1)\n\n# %% [code]\ntest = pd.read_csv(\"test_file.csv\")\n# test = data.drop(columns=['IDLink', 'Title', 'Source', 'Topic', 'PublishDate','Facebook', 'GooglePlus', 'LinkedIn'],axis=1)\n\n# %% [code]\ntest = tokenizer.texts_to_sequences(test['Headline'])\nx_test = pad_sequences(test, maxlen=150)\n\n# %% [code]\ny = model.predict(x_test)\ny = np.argmax(y, axis=1)\n\n# %% [code]\n# Download predictive value\nsub = pd.DataFrame()\nsub['SentimentHeadline'] = y\nsub.to_csv('output.csv', index=False)","execution_count":0,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}